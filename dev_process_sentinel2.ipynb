{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For preparing archive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a few test scenes via GCloud using downloadS2GCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to have...\n",
    "- Separated into L1C prepare vs L2A prepare\n",
    "- If L1C: checked availability on GCLoud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from utils.prepS2 import *\n",
    "from utils.yamlUtils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cogs_dir = \"../S2_Download/\"\n",
    "cogs_dir = \"../S2_ARD/\"\n",
    "sen2cor_8 = \"~/Sen2Cor-02.08.00-Linux64/bin/L2A_Process\"\n",
    "sen2cor_5 = \"~/Sen2Cor-02.08.00-Linux64/bin/L2A_Process\"\n",
    "\n",
    "s3_bucket = \"public-eo-data\"\n",
    "s3_dir = \"catapult/sentinel2/\"\n",
    "aws_creds = pd.read_csv(\"../aws_creds.csv\")\n",
    "access_key = aws_creds.AWSAccessKeyId.values[0]\n",
    "secret_key = aws_creds.AWSSecretKey.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_scenes_list = [\n",
    "    \"S2A_MSIL1C_20180820T223011_N0206_R072_T60KWE_20180821T013410.SAFE\",\n",
    "    \"S2A_MSIL1C_20180820T223011_N0206_R072_T60KWF_20180821T013410.SAFE\",\n",
    "    \"S2A_MSIL1C_20180820T223011_N0206_R072_T60KXE_20180821T013410.SAFE\",\n",
    "    \"S2B_MSIL1C_20190608T221949_N0207_R029_T60KXE_20190608T233246.SAFE\",\n",
    "    \"S2B_MSIL1C_20190608T221949_N0207_R029_T60KXF_20190608T233246.SAFE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene name: S2A_MSIL1C_20180820T223011_T60KWE\n",
      "Download scene dir: ../S2_Download/S2A_MSIL1C_20180820T223011_N0206_R072_T60KWE_20180821T013410.SAFE/\n",
      "Time: 2019-08-27 16:31:28\n",
      "ESA scene already extracted: ../S2_Download/S2A_MSIL1C_20180820T223011_N0206_R072_T60KWE_20180821T013410.SAFE/\n",
      "Time: 2019-08-27 16:31:28\n",
      "L2A temp dir: ../S2_Download/S2A_MSIL2A_20180820T223011_N0206_R072_T60KWE_20180821T013410.SAFE/\n",
      "Time: 2019-08-27 16:31:28\n",
      "COG dir: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_AOT_10m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B02_10m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B03_10m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B04_10m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B08_10m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_WVP_10m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B05_20m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B06_20m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B07_20m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B11_20m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B12_20m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_B8A_20m.tif\n",
      "cog already exists: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_SCL_20m.tif\n",
      "Original metadata file already copied to cog_dir: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/S2A_MSIL2A_20180820T223011_T60KWE_MTD_MSIL2A.xml\n",
      "Preparing scene S2A_MSIL2A_20180820T223011_T60KWE\n",
      "Scene path ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/\n",
      "New uuid: 837c7b11-268b-59cf-bbd5-0fce31b29718\n",
      "Created yaml: ../S2_ARD/S2A_MSIL2A_20180820T223011_T60KWE/datacube-metadata.yaml\n",
      "Time: 2019-08-27 16:31:29\n",
      "Scene name: S2A_MSIL1C_20180820T223011_T60KWF\n",
      "Download scene dir: ../S2_Download/S2A_MSIL1C_20180820T223011_N0206_R072_T60KWF_20180821T013410.SAFE/\n",
      "Time: 2019-08-27 16:31:29\n",
      "Downloading ESA scene zip: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   3%|â–Ž         | 23.1M/744M [00:25<11:50, 1.01MB/s]"
     ]
    }
   ],
   "source": [
    "#lg = \n",
    "\n",
    "for des_scene in des_scenes_list:\n",
    "    \n",
    "    # shorten scene name\n",
    "    scene_name = des_scene[:-21]\n",
    "    scene_name = scene_name[:-17] + scene_name.split('_')[-1]\n",
    "    print ( 'Scene name: {}'.format(scene_name) )\n",
    "    \n",
    "    # find uuid for download via esa hub\n",
    "    s2id = find_s2_uuid(des_scene)\n",
    "\n",
    "    down_dir = non_cogs_dir + des_scene + '/'\n",
    "    print ( 'Download scene dir: {}'.format(down_dir) )\n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "    #download_s2_granule_gcloud(des_scene, non_cogs_dir)\n",
    "    download_extract_s2_esa(s2id, non_cogs_dir, down_dir) # using esa due to gcloud metadata issues + sedas confidence\n",
    "    \n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "    \n",
    "    # process to l2a\n",
    "    l2a_dir = down_dir.replace('_MSIL1C', '_MSIL2A')\n",
    "    print ( 'L2A temp dir: {}'.format(l2a_dir) )\n",
    "    if not os.path.exists(l2a_dir):\n",
    "        sen2cor_correction(sen2cor_8, down_dir, non_cogs_dir) # May need to include try of version 2.5 before certain date - to be determined...\n",
    "    \n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "\n",
    "    # convert to cog\n",
    "    cog_dir = cogs_dir + scene_name.replace('_MSIL1C', '_MSIL2A') + '/'\n",
    "    print ( 'COG dir: {}'.format(cog_dir) )\n",
    "    conv_s2scene_cogs(l2a_dir, cog_dir, scene_name.replace('_MSIL1C', '_MSIL2A'))\n",
    "    \n",
    "    copy_s2_metadata(l2a_dir, cog_dir, scene_name.replace('_MSIL1C', '_MSIL2A'))\n",
    "    \n",
    "    create_yaml(cog_dir, 's2')\n",
    "    \n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d_id, original_scene_dir, scene_name in zip(res.uuid.values, res.filename.values, res.title):\n",
    "    # print ( d_id, original_scene_dir, scene_name )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "    #print (scene_dir)\n",
    "    \n",
    "    tileid = original_scene_dir.split('_')[-2]\n",
    "    \n",
    "    # shorten scene name - wayyyy too long...\n",
    "    scene_name = scene_name[:26] + '_' + tileid\n",
    "    print ( '#### SCENE {} {} of {} ####'.format(scene_name, n, res.shape[0]) )\n",
    "    \n",
    "    # create full path for original and cog scenes\n",
    "    original_scene_dir = non_cog_dir + original_scene_dir + '/'\n",
    "    scene_dir = cog_dir + scene_name + '/'\n",
    "    print ( 'Target original scene dir: {}'.format(original_scene_dir) )\n",
    "    print ( 'Tarket scene dir: {}'.format(scene_dir) )\n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "    \n",
    "    download_extract_s2(d_id, non_cog_dir, original_scene_dir)\n",
    " \n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "\n",
    "    l2a_dir = original_scene_dir.replace('_MSIL1C', '_MSIL2A')[:-39]\n",
    "    \n",
    "    # see if l2a prod exists to avoid running sen2cor unless needed\n",
    "    l2a_dir = glob.glob(original_scene_dir.replace('_MSIL1C', '_MSIL2A')[:-39]+'*')[0]+'/'\n",
    "    print ('pre', l2a_dir )\n",
    "    \n",
    "    if not os.path.exists(l2a_dir):\n",
    "    \n",
    "        sen2cor_correction(sen2cor, original_scene_dir, non_cog_dir)\n",
    "        # shutil.rmtree(original_scene_dir)\n",
    "\n",
    "        l2a_dir = glob.glob(original_scene_dir.replace('_MSIL1C', '_MSIL2A')[:-39]+'*')[0] +'/'\n",
    "        print ('re-defining original to l2a: {}'.format(l2a_dir) )\n",
    "    \n",
    "    original_scene_dir = l2a_dir\n",
    "    \n",
    "    # create (or clear) cog scene directory\n",
    "    if not os.path.exists(scene_dir):\n",
    "        print ( 'Creating scene cog directory: {}'.format(scene_dir) )\n",
    "        os.mkdir(scene_dir)\n",
    "    else:\n",
    "        print ( 'Scene cog directory already exists so passing: {}'.format(scene_dir) )\n",
    "    \n",
    "    copy_s2_metadata(original_scene_dir, scene_dir, scene_name)\n",
    "\n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "    \n",
    "    conv_s2scene_cogs(original_scene_dir, scene_dir, scene_name)\n",
    "\n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "\n",
    "    create_yaml(scene_dir, 's2')\n",
    "    \n",
    "    s3_upload_cogs(glob.glob(scene_dir + '*'), s3_bucket, s3_dir)\n",
    "    \n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "    \n",
    "    print ( 'Nuking original directory: {}'.format(original_scene_dir) )\n",
    "    # shutil.rmtree(original_scene_dir)\n",
    "    \n",
    "    print ( 'Nuking intermediary scene cog dir: {}'.format(scene_dir) )\n",
    "    \n",
    "    print ( ' #### COMPLETED #### '.format(scene_name) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "# eventual MASTER S2 L2A function requiring esa query df and working directoy\n",
    "for d_id, original_scene_dir, scene_name in zip(res.uuid.values, res.filename.values, res.title):\n",
    "    # print ( d_id, original_scene_dir, scene_name )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "    #print (scene_dir)\n",
    "    \n",
    "    tileid = original_scene_dir.split('_')[-2]\n",
    "    \n",
    "    # shorten scene name - wayyyy too long...\n",
    "    scene_name = scene_name[:26] + '_' + tileid\n",
    "    print ( '#### SCENE {} {} of {} ####'.format(scene_name, n, res.shape[0]) )\n",
    "    \n",
    "    # create full path for original and cog scenes\n",
    "    original_scene_dir = non_cog_dir + original_scene_dir + '/'\n",
    "    scene_dir = cog_dir + scene_name + '/'\n",
    "    print ( 'Target original scene dir: {}'.format(original_scene_dir) )\n",
    "    print ( 'Tarket scene dir: {}'.format(scene_dir) )\n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "    \n",
    "    download_extract_s2(d_id, non_cog_dir, original_scene_dir)\n",
    " \n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "\n",
    "    # create (or clear) cog scene directory\n",
    "    if not os.path.exists(scene_dir):\n",
    "        print ( 'Creating scene cog directory: {}'.format(scene_dir) )\n",
    "        os.mkdir(scene_dir)\n",
    "    else:\n",
    "        print ( 'Scene cog directory already exists so passing: {}'.format(scene_dir) )\n",
    "    \n",
    "    copy_s2_metadata(original_scene_dir, scene_dir, scene_name)\n",
    "\n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "    \n",
    "    conv_s2scene_cogs(original_scene_dir, scene_dir, scene_name)\n",
    "\n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "\n",
    "    create_yaml(scene_dir, 's2')\n",
    "    \n",
    "    # s3_upload_cogs(glob.glob(scene_dir + '*'), s3_bucket, s3_dir)\n",
    "    \n",
    "    print ( 'Time: {}'.format(str(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))) )\n",
    "    \n",
    "    print ( 'Nuking original directory: {}'.format(original_scene_dir) )\n",
    "    # shutil.rmtree(original_scene_dir)\n",
    "    \n",
    "    print ( 'Nuking intermediary scene cog dir: {}'.format(scene_dir) )\n",
    "    \n",
    "    print ( ' #### COMPLETED #### '.format(scene_name) )\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using hackathon prepare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For preparing routine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
